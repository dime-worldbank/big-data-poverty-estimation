{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict household poverty from satellite imagery data\n",
    "\n",
    "Using code from run_grid.py, adjust the process to include feature extraction using CNN and changing target to poverty levels.\n",
    "***\n",
    "**ML pipeline steps in detail here:**  \n",
    "1. Import and prep data  \n",
    "    - Import BISP data  \n",
    "    - Choose transformation for target variable (poverty)  \n",
    "    - Import NTL (viirs) data  \n",
    "    - Match BISP HHs to coordinates  \n",
    "    - Join Bisp data and NTL data  \n",
    "    - Map DTL image files to data  \n",
    "<br>\n",
    "2. Use CNN to extract features from DTL  \n",
    "    - Prep DTL, load CNN, and extract features  \n",
    "    - Select extracted features to include using PCA  \n",
    "    - Add selected extracted features to data   \n",
    "<br>\n",
    "3. Split data into test/train sets  \n",
    "***\n",
    "**ML pipline steps handled by run_grid.py:** \n",
    "4. Train and evaluate models (run grid search). For each regressor-hyperparameter combination:  \n",
    "    - Train regressor with given hyperparameters and training data and labels\n",
    "    - Generate predicted labels for test data with trained regressor\n",
    "    - Evaluate regressor-hyperparameter performance against actual test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import configuration file and feature extraction file\n",
    "import config as cf\n",
    "import feature_extraction as fe\n",
    "\n",
    "# Turn off big pink warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display options \n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = -1 \n",
    "\n",
    "# Data file path \n",
    "# final_data_file_path = \"/Users/robmarty/Dropbox/World Bank/IEs/Pakistan Poverty Estimation from Satellites/Data/FinalData\"\n",
    "\n",
    "# Set directory\n",
    "os.chdir(\"/Users/nguyenluong/wb_internship/Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data and prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import BISP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4528, 502)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Predict Changes\n",
    "# DATA_PATH = os.path.join(final_data_file_path, 'BISP','Merged Datasets', 'bisp_socioeconomic_satellite_firstdiff_r13.csv')\n",
    "# DATA_PATH = os.path.join('/Users/robmarty/Desktop/', 'bisp_socioeconomic_satellite_firstdiff_r13.csv')\n",
    "\n",
    "#### Predict Levels\n",
    "DATA_PATH = os.path.join('BISP', 'bisp_socioeconomic_satellite_panel_full_satPovNAsRemoved_1hh.csv')\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3273, 502)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restrict to Year\n",
    "df = df[df['year'] == 2014]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Choose transformation for target (poverty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at distribution\n",
    "plt.hist(df['pscores']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    970\n",
       "2.0    836\n",
       "0.0    701\n",
       "3.0    569\n",
       "4.0    197\n",
       "Name: pscores_bin, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Changes\n",
    "#df['pscores_bin'] = df['pscores'] < 0\n",
    "\n",
    "#### Levels\n",
    "#df = df.loc[df['survey_round'] != 1]\n",
    "#df['pscores_bin'] = df['pscores'] <= (df['pscores'].median())\n",
    "#df['pscores_bin'] = df['pscores_poor']\n",
    "\n",
    "### Target as Quantiles\n",
    "#df['pscores_bin'] = pd.qcut(df['pscores'], 4, labels=False)\n",
    "#df['pscores_2011'].value_counts()\n",
    "#df['pscores_bin'] = df['pscores'] < 0\n",
    "\n",
    "### Binary\n",
    "# df = df[df['pscores_bin'] != 1]\n",
    "# df = df[df['pscores_bin'] != 2]\n",
    "# df['pscores_bin'] = (df['pscores_bin'] == 0)\n",
    "\n",
    "### Clustered by K-Means\n",
    "pscores = df['pscores'].to_numpy().reshape(-1,1)\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='kmeans')\n",
    "df['pscores_bin'] = discretizer.fit_transform(pscores)\n",
    "\n",
    "df.pscores_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['pscores_bin'], range=[0, 4]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Import NTL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_rad_2014</th>\n",
       "      <th>tile_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.179258</td>\n",
       "      <td>42.0</td>\n",
       "      <td>POLYGON ((74.66347 37.06224, 74.67021 37.06224, 74.67021 37.05551, 74.66347 37.05551, 74.66347 37.06224))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207353</td>\n",
       "      <td>42.0</td>\n",
       "      <td>POLYGON ((74.67021 37.06224, 74.67695 37.06224, 74.67695 37.05551, 74.67021 37.05551, 74.67021 37.06224))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   median_rad_2014  tile_id  \\\n",
       "0  0.179258         42.0      \n",
       "1  0.207353         42.0      \n",
       "\n",
       "                                                                                                    geometry  \n",
       "0  POLYGON ((74.66347 37.06224, 74.67021 37.06224, 74.67021 37.05551, 74.66347 37.05551, 74.66347 37.06224))  \n",
       "1  POLYGON ((74.67021 37.06224, 74.67695 37.06224, 74.67695 37.05551, 74.67021 37.05551, 74.67021 37.06224))  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load satellite data\n",
    "viirs_gdf = gpd.read_file('satellite_raw/VIIRS/viirs_annual_polygon.geojson')\n",
    "viirs_gdf = viirs_gdf[['median_rad_2014', 'tile_id', 'geometry']]\n",
    "viirs_gdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Match BISP HHs to Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPSN</th>\n",
       "      <th>GPSE</th>\n",
       "      <th>uid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3349.405</td>\n",
       "      <td>7241.680</td>\n",
       "      <td>104989</td>\n",
       "      <td>33.827917</td>\n",
       "      <td>72.702222</td>\n",
       "      <td>POINT (72.70222 33.82792)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3349.403</td>\n",
       "      <td>7241.698</td>\n",
       "      <td>100389</td>\n",
       "      <td>33.827861</td>\n",
       "      <td>72.702722</td>\n",
       "      <td>POINT (72.70272 33.82786)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3349.392</td>\n",
       "      <td>7241.730</td>\n",
       "      <td>101236</td>\n",
       "      <td>33.827556</td>\n",
       "      <td>72.703611</td>\n",
       "      <td>POINT (72.70361 33.82756)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3349.383</td>\n",
       "      <td>7241.486</td>\n",
       "      <td>105557</td>\n",
       "      <td>33.827306</td>\n",
       "      <td>72.696833</td>\n",
       "      <td>POINT (72.69683 33.82731)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3349.370</td>\n",
       "      <td>7241.639</td>\n",
       "      <td>101915</td>\n",
       "      <td>33.826944</td>\n",
       "      <td>72.701083</td>\n",
       "      <td>POINT (72.70108 33.82694)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GPSN      GPSE     uid        lat        lon                   geometry\n",
       "0  3349.405  7241.680  104989  33.827917  72.702222  POINT (72.70222 33.82792)\n",
       "1  3349.403  7241.698  100389  33.827861  72.702722  POINT (72.70272 33.82786)\n",
       "2  3349.392  7241.730  101236  33.827556  72.703611  POINT (72.70361 33.82756)\n",
       "3  3349.383  7241.486  105557  33.827306  72.696833  POINT (72.69683 33.82731)\n",
       "4  3349.370  7241.639  101915  33.826944  72.701083  POINT (72.70108 33.82694)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BISP coordinate info\n",
    "coords = pd.read_stata('BISP/GPS_uid_crosswalk.dta')\n",
    "\n",
    "from math import floor\n",
    "def get_lat_lon(number):\n",
    "    deg = floor(number / 100)\n",
    "    min = floor(number - (100 * deg))\n",
    "    sec = 100 * (number - (100 * deg) - min)\n",
    "    degree = deg + (min / 60) + (sec / 3600)\n",
    "    return degree\n",
    "\n",
    "# Drop NAs\n",
    "coords = coords[~coords['GPSN'].isna()]\n",
    "\n",
    "# Get lat, lon\n",
    "coords['lat'] = coords['GPSN'].apply(lambda x: get_lat_lon(x))\n",
    "coords['lon'] = coords['GPSE'].apply(lambda x: get_lat_lon(x))\n",
    "\n",
    "# Convert uid to integer\n",
    "coords['uid'] = coords['uid'].astype(int)\n",
    "\n",
    "# Create geopandas\n",
    "coords = gpd.GeoDataFrame(coords, geometry=gpd.points_from_xy(coords['lon'], coords['lat']))\n",
    "coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3273, 508)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match coords to HHs in df\n",
    "gdf_bisp = coords.merge(df, left_on='uid', right_on='uid')\n",
    "gdf_bisp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Join Bisp data and NTL data\n",
    "Bisp HHs located in an NTL tile/poly are linked to that NTL radiance value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join HHs with satellite viirs\n",
    "gdf = gpd.sjoin(viirs_gdf, gdf_bisp, how=\"inner\", op='intersects').reset_index(drop=True)\n",
    "# Reset index because multiple HHs may belong to one NTL tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3259, 511)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([40., 36., 38., 37., 32., 33., 31., 34., 28., 29., 30., 27., 26.,\n",
       "       25., 23., 20., 21., 22., 24., 19., 15., 14., 13.,  9.,  8., 10.,\n",
       "        1.,  2.])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect range of tiles represented\n",
    "print(gdf.shape)\n",
    "gdf['tile_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Map DTL image files to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTL_directory = os.path.join('satellite_raw', 'Landsat', '2014')\n",
    "DLT, processed_gdf = fe.map_DTL_NTL(gdf, DTL_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3223, 511)\n",
      "Note: 36 observations were dropped due to irregular DTL sizes\n"
     ]
    }
   ],
   "source": [
    "print(processed_gdf.shape)\n",
    "print('Note: {} observations were dropped due to irregular DTL sizes'.format(gdf.shape[0] - processed_gdf.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Select Columns\n",
    "df_viirs = processed_gdf.filter(regex='viirs').filter(regex='_2km')\n",
    "df_landsat = processed_gdf.filter(regex='^b').filter(regex='_1km')\n",
    "df_osm = processed_gdf.filter(regex='fclass').filter(regex='meters')\n",
    "df_facebook = processed_gdf.filter(regex='^estimate_dau')\n",
    "\n",
    "df_y = processed_gdf[['pscores', 'pscores_bin']]\n",
    "\n",
    "# Reset index because 36 observations and indexes dropped throughout\n",
    "df_final = df_y.join(df_osm).join(df_facebook).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use CNN to extract features from DTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prep DTL, load CNN, and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTL after reshaping: (3223, 25, 26, 7)\n"
     ]
    }
   ],
   "source": [
    "# Reshape DTL like in CNN training\n",
    "height, width, channels = 25, 26, 7\n",
    "DLT = DLT.reshape((DLT.shape[0], height, width, channels))\n",
    "print('DTL after reshaping: {}'.format(DLT.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save objects for later\n",
    "#processed_gdf.to_pickle('saved_objects/processed_gdf.pkl')\n",
    "#df_final.to_pickle('saved_objects/df_final.pkl')\n",
    "#np.save('saved_objects/poverty_DLT', DLT)\n",
    "#viirs_gdf.to_pickle('saved_objects/viirs_gdf.pkl')\n",
    "\n",
    "### Restart here\n",
    "processed_gdf = pd.read_pickle('saved_objects/processed_gdf.pkl')\n",
    "df_final = pd.read_pickle('saved_objects/df_final.pkl') #target = pscores_bin k-means clustering like NLT\n",
    "DLT = np.load('saved_objects/poverty_DLT.npy')\n",
    "#viirs_gdf = pd.read_pickle('saved_objects/viirs_gdf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 21, 22, 64)        11264     \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 10, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten1 (Flatten)           (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 100)               704100    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 715,869\n",
      "Trainable params: 715,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load CNN\n",
    "from keras.models import load_model\n",
    "model = load_model('best_CNN.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>feat_33</th>\n",
       "      <th>feat_34</th>\n",
       "      <th>feat_35</th>\n",
       "      <th>feat_36</th>\n",
       "      <th>feat_37</th>\n",
       "      <th>feat_38</th>\n",
       "      <th>feat_39</th>\n",
       "      <th>feat_40</th>\n",
       "      <th>feat_41</th>\n",
       "      <th>feat_42</th>\n",
       "      <th>feat_43</th>\n",
       "      <th>feat_44</th>\n",
       "      <th>feat_45</th>\n",
       "      <th>feat_46</th>\n",
       "      <th>feat_47</th>\n",
       "      <th>feat_48</th>\n",
       "      <th>feat_49</th>\n",
       "      <th>feat_50</th>\n",
       "      <th>feat_51</th>\n",
       "      <th>feat_52</th>\n",
       "      <th>feat_53</th>\n",
       "      <th>feat_54</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>feat_65</th>\n",
       "      <th>feat_66</th>\n",
       "      <th>feat_67</th>\n",
       "      <th>feat_68</th>\n",
       "      <th>feat_69</th>\n",
       "      <th>feat_70</th>\n",
       "      <th>feat_71</th>\n",
       "      <th>feat_72</th>\n",
       "      <th>feat_73</th>\n",
       "      <th>feat_74</th>\n",
       "      <th>feat_75</th>\n",
       "      <th>feat_76</th>\n",
       "      <th>feat_77</th>\n",
       "      <th>feat_78</th>\n",
       "      <th>feat_79</th>\n",
       "      <th>feat_80</th>\n",
       "      <th>feat_81</th>\n",
       "      <th>feat_82</th>\n",
       "      <th>feat_83</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>feat_94</th>\n",
       "      <th>feat_95</th>\n",
       "      <th>feat_96</th>\n",
       "      <th>feat_97</th>\n",
       "      <th>feat_98</th>\n",
       "      <th>feat_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2366.600586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2522.061035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3883.045410</td>\n",
       "      <td>1161.409058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>238.642548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1133.368286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.302917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3263.840088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4744.113281</td>\n",
       "      <td>1212.678589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.813400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2941.686523</td>\n",
       "      <td>783.1427</td>\n",
       "      <td>2031.683960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1191.658081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2260.906006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>823.855957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5688.450684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2094.69873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.956139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.866501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>774.081848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.622139</td>\n",
       "      <td>888.501709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2103.291504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>709.257812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1090.323486</td>\n",
       "      <td>940.399719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>543.331787</td>\n",
       "      <td>2957.527100</td>\n",
       "      <td>1878.533325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.681442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2097.463135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>363.357880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>733.075867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1149.308472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>555.367981</td>\n",
       "      <td>2108.306396</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1365.018066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.2397</td>\n",
       "      <td>339.253754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2376.997070</td>\n",
       "      <td>403.180664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4283.085938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>575.385620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>801.021912</td>\n",
       "      <td>418.039246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>976.908203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.494598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>850.374268</td>\n",
       "      <td>410.606262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499.948822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>492.802155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2059.481201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.064293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.494598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>850.374268</td>\n",
       "      <td>410.606262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499.948822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>492.802155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2059.481201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.064293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.494598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>850.374268</td>\n",
       "      <td>410.606262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>499.948822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>492.802155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2059.481201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.064293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.082275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>823.936157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.686569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>189.586395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>309.118286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.101776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.699986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.783386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.830994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.013618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.082275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>823.936157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.686569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>189.586395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>309.118286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.101776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.699986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.783386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.830994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.013618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.082275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>823.936157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212.686569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>189.586395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>309.118286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.101776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.699986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.783386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.830994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.013618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>247.230179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>661.137329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1491.912964</td>\n",
       "      <td>283.338104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>393.611816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.461487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>507.391541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.098434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>222.963379</td>\n",
       "      <td>633.244629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>757.303650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2266.785645</td>\n",
       "      <td>238.389755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>266.263641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386.294189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1498.691040</td>\n",
       "      <td>481.650238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>887.064575</td>\n",
       "      <td>2355.174561</td>\n",
       "      <td>954.583984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>746.300720</td>\n",
       "      <td>367.858521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.571602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>599.639038</td>\n",
       "      <td>2150.950684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2107.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.521240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>361.428619</td>\n",
       "      <td>1008.329590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>984.627808</td>\n",
       "      <td>45.766720</td>\n",
       "      <td>2387.501221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3017.253418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2601.618164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1572.632202</td>\n",
       "      <td>309.331818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5425.923828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.916046</td>\n",
       "      <td>100.641151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1210.210815</td>\n",
       "      <td>36.283581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3060.504639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2285.758057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3223 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feat_0  feat_1  feat_2       feat_3       feat_4      feat_5  \\\n",
       "0     0.0     0.0     0.0     2366.600586  0.000000     0.000000     \n",
       "1     0.0     0.0     0.0     0.000000     709.257812   0.000000     \n",
       "2     0.0     0.0     0.0     0.000000     0.000000     0.000000     \n",
       "3     0.0     0.0     0.0     0.000000     0.000000     0.000000     \n",
       "4     0.0     0.0     0.0     0.000000     0.000000     0.000000     \n",
       "...   ...     ...     ...          ...          ...          ...     \n",
       "3218  0.0     0.0     0.0     0.000000     0.000000     0.000000     \n",
       "3219  0.0     0.0     0.0     0.000000     0.000000     0.000000     \n",
       "3220  0.0     0.0     0.0     0.000000     0.000000     0.000000     \n",
       "3221  0.0     0.0     0.0     0.000000     247.230179   0.000000     \n",
       "3222  0.0     0.0     0.0     0.000000     1498.691040  481.650238   \n",
       "\n",
       "          feat_6  feat_7  feat_8  feat_9  feat_10      feat_11     feat_12  \\\n",
       "0     0.000000    0.0     0.0     0.0     0.0      0.000000     0.000000     \n",
       "1     0.000000    0.0     0.0     0.0     0.0      1090.323486  940.399719   \n",
       "2     0.000000    0.0     0.0     0.0     0.0      145.494598   0.000000     \n",
       "3     0.000000    0.0     0.0     0.0     0.0      145.494598   0.000000     \n",
       "4     0.000000    0.0     0.0     0.0     0.0      145.494598   0.000000     \n",
       "...        ...    ...     ...     ...     ...             ...        ...     \n",
       "3218  0.000000    0.0     0.0     0.0     0.0      111.082275   0.000000     \n",
       "3219  0.000000    0.0     0.0     0.0     0.0      111.082275   0.000000     \n",
       "3220  0.000000    0.0     0.0     0.0     0.0      111.082275   0.000000     \n",
       "3221  661.137329  0.0     0.0     0.0     0.0      0.000000     0.000000     \n",
       "3222  0.000000    0.0     0.0     0.0     0.0      0.000000     0.000000     \n",
       "\n",
       "          feat_13  feat_14  feat_15     feat_16      feat_17      feat_18  \\\n",
       "0     2522.061035  0.0      0.0      0.000000    3883.045410  1161.409058   \n",
       "1     0.000000     0.0      0.0      543.331787  2957.527100  1878.533325   \n",
       "2     0.000000     0.0      0.0      0.000000    850.374268   410.606262    \n",
       "3     0.000000     0.0      0.0      0.000000    850.374268   410.606262    \n",
       "4     0.000000     0.0      0.0      0.000000    850.374268   410.606262    \n",
       "...        ...     ...      ...           ...           ...          ...    \n",
       "3218  0.000000     0.0      0.0      0.000000    823.936157   0.000000      \n",
       "3219  0.000000     0.0      0.0      0.000000    823.936157   0.000000      \n",
       "3220  0.000000     0.0      0.0      0.000000    823.936157   0.000000      \n",
       "3221  0.000000     0.0      0.0      0.000000    1491.912964  283.338104    \n",
       "3222  0.000000     0.0      0.0      887.064575  2355.174561  954.583984    \n",
       "\n",
       "      feat_19  feat_20  feat_21    feat_22     feat_23  feat_24  feat_25  \\\n",
       "0     0.0      0.0      0.0      0.000000   238.642548  0.0      0.0       \n",
       "1     0.0      0.0      0.0      43.681442  0.000000    0.0      0.0       \n",
       "2     0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "3     0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "4     0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "...   ...      ...      ...           ...        ...    ...      ...       \n",
       "3218  0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "3219  0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "3220  0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "3221  0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "3222  0.0      0.0      0.0      0.000000   0.000000    0.0      0.0       \n",
       "\n",
       "      feat_26  feat_27     feat_28     feat_29  feat_30      feat_31  feat_32  \\\n",
       "0     0.0      0.0      0.000000    0.000000    0.0      1133.368286  0.0       \n",
       "1     0.0      0.0      0.000000    0.000000    0.0      2097.463135  0.0       \n",
       "2     0.0      0.0      0.000000    0.000000    0.0      0.000000     0.0       \n",
       "3     0.0      0.0      0.000000    0.000000    0.0      0.000000     0.0       \n",
       "4     0.0      0.0      0.000000    0.000000    0.0      0.000000     0.0       \n",
       "...   ...      ...           ...         ...    ...           ...     ...       \n",
       "3218  0.0      0.0      212.686569  0.000000    0.0      0.000000     0.0       \n",
       "3219  0.0      0.0      212.686569  0.000000    0.0      0.000000     0.0       \n",
       "3220  0.0      0.0      212.686569  0.000000    0.0      0.000000     0.0       \n",
       "3221  0.0      0.0      393.611816  0.000000    0.0      235.461487   0.0       \n",
       "3222  0.0      0.0      746.300720  367.858521  0.0      107.571602   0.0       \n",
       "\n",
       "         feat_33      feat_34  feat_35      feat_36     feat_37  feat_38  \\\n",
       "0     0.000000    0.000000     0.0      0.000000     580.302917  0.0       \n",
       "1     0.000000    0.000000     0.0      363.357880   0.000000    0.0       \n",
       "2     0.000000    0.000000     0.0      0.000000     0.000000    0.0       \n",
       "3     0.000000    0.000000     0.0      0.000000     0.000000    0.0       \n",
       "4     0.000000    0.000000     0.0      0.000000     0.000000    0.0       \n",
       "...        ...         ...     ...           ...          ...    ...       \n",
       "3218  0.000000    189.586395   0.0      0.000000     0.000000    0.0       \n",
       "3219  0.000000    189.586395   0.0      0.000000     0.000000    0.0       \n",
       "3220  0.000000    189.586395   0.0      0.000000     0.000000    0.0       \n",
       "3221  0.000000    507.391541   0.0      0.000000     0.000000    0.0       \n",
       "3222  599.639038  2150.950684  0.0      2107.012695  0.000000    0.0       \n",
       "\n",
       "      feat_39  feat_40      feat_41  feat_42      feat_43      feat_44  \\\n",
       "0     0.0      0.0      3263.840088  0.0      4744.113281  1212.678589   \n",
       "1     0.0      0.0      0.000000     0.0      733.075867   0.000000      \n",
       "2     0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "3     0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "4     0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "...   ...      ...           ...     ...           ...          ...      \n",
       "3218  0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "3219  0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "3220  0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "3221  0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "3222  0.0      0.0      0.000000     0.0      0.000000     0.000000      \n",
       "\n",
       "          feat_45  feat_46     feat_47      feat_48      feat_49   feat_50  \\\n",
       "0     0.000000     0.0      255.813400  0.000000     2941.686523  783.1427   \n",
       "1     1149.308472  0.0      0.000000    555.367981   2108.306396  0.0000     \n",
       "2     0.000000     0.0      0.000000    499.948822   0.000000     0.0000     \n",
       "3     0.000000     0.0      0.000000    499.948822   0.000000     0.0000     \n",
       "4     0.000000     0.0      0.000000    499.948822   0.000000     0.0000     \n",
       "...        ...     ...           ...           ...        ...        ...     \n",
       "3218  0.000000     0.0      0.000000    0.000000     0.000000     0.0000     \n",
       "3219  0.000000     0.0      0.000000    0.000000     0.000000     0.0000     \n",
       "3220  0.000000     0.0      0.000000    0.000000     0.000000     0.0000     \n",
       "3221  0.000000     0.0      92.098434   0.000000     0.000000     0.0000     \n",
       "3222  113.521240   0.0      361.428619  1008.329590  0.000000     0.0000     \n",
       "\n",
       "          feat_51     feat_52      feat_53      feat_54  feat_55      feat_56  \\\n",
       "0     2031.683960  0.000000    0.000000     1191.658081  0.0      0.000000      \n",
       "1     1365.018066  0.000000    0.000000     0.000000     0.0      0.000000      \n",
       "2     492.802155   0.000000    0.000000     0.000000     0.0      0.000000      \n",
       "3     492.802155   0.000000    0.000000     0.000000     0.0      0.000000      \n",
       "4     492.802155   0.000000    0.000000     0.000000     0.0      0.000000      \n",
       "...          ...        ...         ...          ...     ...           ...      \n",
       "3218  0.000000     309.118286  0.000000     0.000000     0.0      0.000000      \n",
       "3219  0.000000     309.118286  0.000000     0.000000     0.0      0.000000      \n",
       "3220  0.000000     309.118286  0.000000     0.000000     0.0      0.000000      \n",
       "3221  222.963379   633.244629  0.000000     0.000000     0.0      0.000000      \n",
       "3222  984.627808   45.766720   2387.501221  0.000000     0.0      3017.253418   \n",
       "\n",
       "          feat_57  feat_58      feat_59  feat_60  feat_61  feat_62   feat_63  \\\n",
       "0     2260.906006  0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "1     0.000000     0.0      0.000000     0.0      0.0      0.0      185.2397   \n",
       "2     0.000000     0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "3     0.000000     0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "4     0.000000     0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "...        ...     ...           ...     ...      ...      ...         ...     \n",
       "3218  181.101776   0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "3219  181.101776   0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "3220  181.101776   0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "3221  757.303650   0.0      0.000000     0.0      0.0      0.0      0.0000     \n",
       "3222  0.000000     0.0      2601.618164  0.0      0.0      0.0      0.0000     \n",
       "\n",
       "         feat_64  feat_65      feat_66      feat_67     feat_68  feat_69  \\\n",
       "0     0.000000    0.0      823.855957   0.000000     0.000000    0.0       \n",
       "1     339.253754  0.0      0.000000     2376.997070  403.180664  0.0       \n",
       "2     0.000000    0.0      0.000000     0.000000     0.000000    0.0       \n",
       "3     0.000000    0.0      0.000000     0.000000     0.000000    0.0       \n",
       "4     0.000000    0.0      0.000000     0.000000     0.000000    0.0       \n",
       "...        ...    ...           ...          ...          ...    ...       \n",
       "3218  0.000000    0.0      0.000000     0.000000     6.699986    0.0       \n",
       "3219  0.000000    0.0      0.000000     0.000000     6.699986    0.0       \n",
       "3220  0.000000    0.0      0.000000     0.000000     6.699986    0.0       \n",
       "3221  0.000000    0.0      0.000000     0.000000     0.000000    0.0       \n",
       "3222  0.000000    0.0      1572.632202  309.331818   0.000000    0.0       \n",
       "\n",
       "      feat_70  feat_71  feat_72      feat_73     feat_74  feat_75  feat_76  \\\n",
       "0     0.0      0.0      0.0      5688.450684  0.000000    0.0      0.0       \n",
       "1     0.0      0.0      0.0      4283.085938  0.000000    0.0      0.0       \n",
       "2     0.0      0.0      0.0      2059.481201  0.000000    0.0      0.0       \n",
       "3     0.0      0.0      0.0      2059.481201  0.000000    0.0      0.0       \n",
       "4     0.0      0.0      0.0      2059.481201  0.000000    0.0      0.0       \n",
       "...   ...      ...      ...              ...       ...    ...      ...       \n",
       "3218  0.0      0.0      0.0      1016.783386  0.000000    0.0      0.0       \n",
       "3219  0.0      0.0      0.0      1016.783386  0.000000    0.0      0.0       \n",
       "3220  0.0      0.0      0.0      1016.783386  0.000000    0.0      0.0       \n",
       "3221  0.0      0.0      0.0      2266.785645  238.389755  0.0      0.0       \n",
       "3222  0.0      0.0      0.0      5425.923828  0.000000    0.0      0.0       \n",
       "\n",
       "      feat_77     feat_78     feat_79  feat_80     feat_81  feat_82  feat_83  \\\n",
       "0     0.0      0.000000    0.000000    0.0      2094.69873  0.0      0.0       \n",
       "1     0.0      0.000000    575.385620  0.0      0.00000     0.0      0.0       \n",
       "2     0.0      0.000000    5.064293    0.0      0.00000     0.0      0.0       \n",
       "3     0.0      0.000000    5.064293    0.0      0.00000     0.0      0.0       \n",
       "4     0.0      0.000000    5.064293    0.0      0.00000     0.0      0.0       \n",
       "...   ...           ...         ...    ...          ...     ...      ...       \n",
       "3218  0.0      0.000000    262.830994  0.0      0.00000     0.0      0.0       \n",
       "3219  0.0      0.000000    262.830994  0.0      0.00000     0.0      0.0       \n",
       "3220  0.0      0.000000    262.830994  0.0      0.00000     0.0      0.0       \n",
       "3221  0.0      0.000000    266.263641  0.0      0.00000     0.0      0.0       \n",
       "3222  0.0      353.916046  100.641151  0.0      0.00000     0.0      0.0       \n",
       "\n",
       "      feat_84  feat_85  feat_86    feat_87  feat_88  feat_89  feat_90  \\\n",
       "0     0.0      0.0      0.0      76.956139  0.0      0.0      0.0       \n",
       "1     0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "2     0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "3     0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "4     0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "...   ...      ...      ...           ...   ...      ...      ...       \n",
       "3218  0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "3219  0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "3220  0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "3221  0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "3222  0.0      0.0      0.0      0.000000   0.0      0.0      0.0       \n",
       "\n",
       "         feat_91     feat_92  feat_93      feat_94    feat_95    feat_96  \\\n",
       "0     50.866501   0.000000    0.0      774.081848   0.000000   64.622139   \n",
       "1     801.021912  418.039246  0.0      0.000000     0.000000   0.000000    \n",
       "2     0.000000    0.000000    0.0      0.000000     0.000000   0.000000    \n",
       "3     0.000000    0.000000    0.0      0.000000     0.000000   0.000000    \n",
       "4     0.000000    0.000000    0.0      0.000000     0.000000   0.000000    \n",
       "...        ...         ...    ...           ...          ...        ...    \n",
       "3218  0.000000    0.000000    0.0      0.000000     0.000000   0.000000    \n",
       "3219  0.000000    0.000000    0.0      0.000000     0.000000   0.000000    \n",
       "3220  0.000000    0.000000    0.0      0.000000     0.000000   0.000000    \n",
       "3221  0.000000    0.000000    0.0      0.000000     0.000000   0.000000    \n",
       "3222  0.000000    0.000000    0.0      1210.210815  36.283581  0.000000    \n",
       "\n",
       "          feat_97  feat_98      feat_99  \n",
       "0     888.501709   0.0      2103.291504  \n",
       "1     0.000000     0.0      976.908203   \n",
       "2     0.000000     0.0      0.000000     \n",
       "3     0.000000     0.0      0.000000     \n",
       "4     0.000000     0.0      0.000000     \n",
       "...        ...     ...           ...     \n",
       "3218  0.000000     0.0      66.013618    \n",
       "3219  0.000000     0.0      66.013618    \n",
       "3220  0.000000     0.0      66.013618    \n",
       "3221  0.000000     0.0      386.294189   \n",
       "3222  3060.504639  0.0      2285.758057  \n",
       "\n",
       "[3223 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features\n",
    "df_features = fe.extract_features(model, DLT, 'dense1')\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Select extracted features to include using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.46551034 0.20630388 0.0650542  0.06242413 0.03172478 0.02843886\n",
      " 0.01694803 0.0145783  0.01393102 0.01331443]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc_0</th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "      <th>pc_3</th>\n",
       "      <th>pc_4</th>\n",
       "      <th>pc_5</th>\n",
       "      <th>pc_6</th>\n",
       "      <th>pc_7</th>\n",
       "      <th>pc_8</th>\n",
       "      <th>pc_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7585.058105</td>\n",
       "      <td>3182.068115</td>\n",
       "      <td>3086.048584</td>\n",
       "      <td>362.265961</td>\n",
       "      <td>-3541.786865</td>\n",
       "      <td>651.376221</td>\n",
       "      <td>-972.357178</td>\n",
       "      <td>1833.468628</td>\n",
       "      <td>1186.738892</td>\n",
       "      <td>-1297.999023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4837.711914</td>\n",
       "      <td>1970.663086</td>\n",
       "      <td>894.096558</td>\n",
       "      <td>1319.076172</td>\n",
       "      <td>118.324799</td>\n",
       "      <td>-1669.840210</td>\n",
       "      <td>-379.808899</td>\n",
       "      <td>-204.805176</td>\n",
       "      <td>-774.786316</td>\n",
       "      <td>-286.413635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.174561</td>\n",
       "      <td>-1018.420105</td>\n",
       "      <td>222.295380</td>\n",
       "      <td>-434.918549</td>\n",
       "      <td>-168.401978</td>\n",
       "      <td>-306.019714</td>\n",
       "      <td>549.116760</td>\n",
       "      <td>-371.548248</td>\n",
       "      <td>-162.468506</td>\n",
       "      <td>139.214325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.174561</td>\n",
       "      <td>-1018.420105</td>\n",
       "      <td>222.295380</td>\n",
       "      <td>-434.918549</td>\n",
       "      <td>-168.401978</td>\n",
       "      <td>-306.019714</td>\n",
       "      <td>549.116760</td>\n",
       "      <td>-371.548248</td>\n",
       "      <td>-162.468506</td>\n",
       "      <td>139.214325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.174561</td>\n",
       "      <td>-1018.420105</td>\n",
       "      <td>222.295380</td>\n",
       "      <td>-434.918549</td>\n",
       "      <td>-168.401978</td>\n",
       "      <td>-306.019714</td>\n",
       "      <td>549.116760</td>\n",
       "      <td>-371.548248</td>\n",
       "      <td>-162.468506</td>\n",
       "      <td>139.214325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>1313.573364</td>\n",
       "      <td>-1360.943115</td>\n",
       "      <td>33.014164</td>\n",
       "      <td>-55.349747</td>\n",
       "      <td>101.148880</td>\n",
       "      <td>6.004326</td>\n",
       "      <td>175.159637</td>\n",
       "      <td>-369.176514</td>\n",
       "      <td>208.163177</td>\n",
       "      <td>113.497681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>1313.573364</td>\n",
       "      <td>-1360.943115</td>\n",
       "      <td>33.014164</td>\n",
       "      <td>-55.349747</td>\n",
       "      <td>101.148880</td>\n",
       "      <td>6.004326</td>\n",
       "      <td>175.159637</td>\n",
       "      <td>-369.176514</td>\n",
       "      <td>208.163177</td>\n",
       "      <td>113.497681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>1313.573364</td>\n",
       "      <td>-1360.943115</td>\n",
       "      <td>33.014164</td>\n",
       "      <td>-55.349747</td>\n",
       "      <td>101.148880</td>\n",
       "      <td>6.004326</td>\n",
       "      <td>175.159637</td>\n",
       "      <td>-369.176514</td>\n",
       "      <td>208.163177</td>\n",
       "      <td>113.497681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>2542.413330</td>\n",
       "      <td>-794.536133</td>\n",
       "      <td>245.316132</td>\n",
       "      <td>-268.127106</td>\n",
       "      <td>102.290421</td>\n",
       "      <td>-488.487335</td>\n",
       "      <td>119.743805</td>\n",
       "      <td>-526.833801</td>\n",
       "      <td>833.238159</td>\n",
       "      <td>-147.713013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>6699.755371</td>\n",
       "      <td>2747.739746</td>\n",
       "      <td>-3168.123047</td>\n",
       "      <td>-2014.046753</td>\n",
       "      <td>2157.230225</td>\n",
       "      <td>290.348938</td>\n",
       "      <td>2590.269287</td>\n",
       "      <td>625.252075</td>\n",
       "      <td>-120.761475</td>\n",
       "      <td>-931.633545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3223 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pc_0         pc_1         pc_2         pc_3         pc_4  \\\n",
       "0     7585.058105  3182.068115  3086.048584  362.265961  -3541.786865   \n",
       "1     4837.711914  1970.663086  894.096558   1319.076172  118.324799    \n",
       "2     2020.174561 -1018.420105  222.295380  -434.918549  -168.401978    \n",
       "3     2020.174561 -1018.420105  222.295380  -434.918549  -168.401978    \n",
       "4     2020.174561 -1018.420105  222.295380  -434.918549  -168.401978    \n",
       "...           ...          ...         ...          ...          ...    \n",
       "3218  1313.573364 -1360.943115  33.014164   -55.349747    101.148880    \n",
       "3219  1313.573364 -1360.943115  33.014164   -55.349747    101.148880    \n",
       "3220  1313.573364 -1360.943115  33.014164   -55.349747    101.148880    \n",
       "3221  2542.413330 -794.536133   245.316132  -268.127106   102.290421    \n",
       "3222  6699.755371  2747.739746 -3168.123047 -2014.046753  2157.230225   \n",
       "\n",
       "             pc_5         pc_6         pc_7         pc_8         pc_9  \n",
       "0     651.376221  -972.357178   1833.468628  1186.738892 -1297.999023  \n",
       "1    -1669.840210 -379.808899  -204.805176  -774.786316  -286.413635   \n",
       "2    -306.019714   549.116760  -371.548248  -162.468506   139.214325   \n",
       "3    -306.019714   549.116760  -371.548248  -162.468506   139.214325   \n",
       "4    -306.019714   549.116760  -371.548248  -162.468506   139.214325   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "3218  6.004326     175.159637  -369.176514   208.163177   113.497681   \n",
       "3219  6.004326     175.159637  -369.176514   208.163177   113.497681   \n",
       "3220  6.004326     175.159637  -369.176514   208.163177   113.497681   \n",
       "3221 -488.487335   119.743805  -526.833801   833.238159  -147.713013   \n",
       "3222  290.348938   2590.269287  625.252075  -120.761475  -931.633545   \n",
       "\n",
       "[3223 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(df_features)\n",
    "print('Explained variance ratio: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "features_pca = pca.transform(df_features)\n",
    "column_names = ['pc_%01d' %i for i in range(0,10)]\n",
    "df_features_pca = pd.DataFrame(data=features_pca, columns=column_names)\n",
    "df_features_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Add selected extracted features to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pscores_bin</th>\n",
       "      <th>dist_osm_fclass_tertiary_meters</th>\n",
       "      <th>dist_osm_fclass_secondary_meters</th>\n",
       "      <th>dist_osm_fclass_residential_meters</th>\n",
       "      <th>dist_osm_fclass_trunk_meters</th>\n",
       "      <th>dist_osm_fclass_primary_meters</th>\n",
       "      <th>dist_osm_fclass_unclassified_meters</th>\n",
       "      <th>dist_osm_fclass_service_meters</th>\n",
       "      <th>dist_osm_fclass_motorway_meters</th>\n",
       "      <th>dist_osm_fclass_living_street_meters</th>\n",
       "      <th>estimate_dau_all</th>\n",
       "      <th>estimate_dau_male</th>\n",
       "      <th>estimate_dau_female</th>\n",
       "      <th>pc_0</th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "      <th>pc_3</th>\n",
       "      <th>pc_4</th>\n",
       "      <th>pc_5</th>\n",
       "      <th>pc_6</th>\n",
       "      <th>pc_7</th>\n",
       "      <th>pc_8</th>\n",
       "      <th>pc_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3792.357952</td>\n",
       "      <td>35917.095934</td>\n",
       "      <td>43.583917</td>\n",
       "      <td>13075.891660</td>\n",
       "      <td>11.621799</td>\n",
       "      <td>11474.921382</td>\n",
       "      <td>8160.699002</td>\n",
       "      <td>149159.485989</td>\n",
       "      <td>15756.970525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7585.058105</td>\n",
       "      <td>3182.068115</td>\n",
       "      <td>3086.048584</td>\n",
       "      <td>362.265961</td>\n",
       "      <td>-3541.786865</td>\n",
       "      <td>651.376221</td>\n",
       "      <td>-972.357178</td>\n",
       "      <td>1833.468628</td>\n",
       "      <td>1186.738892</td>\n",
       "      <td>-1297.999023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3165.949020</td>\n",
       "      <td>36611.060520</td>\n",
       "      <td>4.980330</td>\n",
       "      <td>12488.112391</td>\n",
       "      <td>87.400393</td>\n",
       "      <td>11824.485331</td>\n",
       "      <td>7700.984802</td>\n",
       "      <td>148553.674436</td>\n",
       "      <td>15796.078642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4837.711914</td>\n",
       "      <td>1970.663086</td>\n",
       "      <td>894.096558</td>\n",
       "      <td>1319.076172</td>\n",
       "      <td>118.324799</td>\n",
       "      <td>-1669.840210</td>\n",
       "      <td>-379.808899</td>\n",
       "      <td>-204.805176</td>\n",
       "      <td>-774.786316</td>\n",
       "      <td>-286.413635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3014.708699</td>\n",
       "      <td>36518.572312</td>\n",
       "      <td>73.896161</td>\n",
       "      <td>12772.653817</td>\n",
       "      <td>375.076111</td>\n",
       "      <td>11427.455346</td>\n",
       "      <td>7392.205527</td>\n",
       "      <td>148370.227522</td>\n",
       "      <td>16233.078724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.174561</td>\n",
       "      <td>-1018.420105</td>\n",
       "      <td>222.295380</td>\n",
       "      <td>-434.918549</td>\n",
       "      <td>-168.401978</td>\n",
       "      <td>-306.019714</td>\n",
       "      <td>549.116760</td>\n",
       "      <td>-371.548248</td>\n",
       "      <td>-162.468506</td>\n",
       "      <td>139.214325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3066.888739</td>\n",
       "      <td>36474.995373</td>\n",
       "      <td>24.791045</td>\n",
       "      <td>12796.758541</td>\n",
       "      <td>400.119781</td>\n",
       "      <td>11423.093075</td>\n",
       "      <td>7441.220550</td>\n",
       "      <td>148422.609270</td>\n",
       "      <td>16205.552093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.174561</td>\n",
       "      <td>-1018.420105</td>\n",
       "      <td>222.295380</td>\n",
       "      <td>-434.918549</td>\n",
       "      <td>-168.401978</td>\n",
       "      <td>-306.019714</td>\n",
       "      <td>549.116760</td>\n",
       "      <td>-371.548248</td>\n",
       "      <td>-162.468506</td>\n",
       "      <td>139.214325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3089.591174</td>\n",
       "      <td>36450.085615</td>\n",
       "      <td>0.208842</td>\n",
       "      <td>12817.844473</td>\n",
       "      <td>421.441879</td>\n",
       "      <td>11408.873066</td>\n",
       "      <td>7457.007066</td>\n",
       "      <td>148443.676013</td>\n",
       "      <td>16204.936983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.174561</td>\n",
       "      <td>-1018.420105</td>\n",
       "      <td>222.295380</td>\n",
       "      <td>-434.918549</td>\n",
       "      <td>-168.401978</td>\n",
       "      <td>-306.019714</td>\n",
       "      <td>549.116760</td>\n",
       "      <td>-371.548248</td>\n",
       "      <td>-162.468506</td>\n",
       "      <td>139.214325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1914.085972</td>\n",
       "      <td>48633.104101</td>\n",
       "      <td>2016.437865</td>\n",
       "      <td>631.035101</td>\n",
       "      <td>72286.291293</td>\n",
       "      <td>1445.935959</td>\n",
       "      <td>6340.847990</td>\n",
       "      <td>95081.405194</td>\n",
       "      <td>2500.320481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1313.573364</td>\n",
       "      <td>-1360.943115</td>\n",
       "      <td>33.014164</td>\n",
       "      <td>-55.349747</td>\n",
       "      <td>101.148880</td>\n",
       "      <td>6.004326</td>\n",
       "      <td>175.159637</td>\n",
       "      <td>-369.176514</td>\n",
       "      <td>208.163177</td>\n",
       "      <td>113.497681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1649.096528</td>\n",
       "      <td>48705.592566</td>\n",
       "      <td>1736.509063</td>\n",
       "      <td>365.050566</td>\n",
       "      <td>72204.953064</td>\n",
       "      <td>1248.008186</td>\n",
       "      <td>6614.281203</td>\n",
       "      <td>94930.990709</td>\n",
       "      <td>2226.293917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1313.573364</td>\n",
       "      <td>-1360.943115</td>\n",
       "      <td>33.014164</td>\n",
       "      <td>-55.349747</td>\n",
       "      <td>101.148880</td>\n",
       "      <td>6.004326</td>\n",
       "      <td>175.159637</td>\n",
       "      <td>-369.176514</td>\n",
       "      <td>208.163177</td>\n",
       "      <td>113.497681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1598.886011</td>\n",
       "      <td>48676.729092</td>\n",
       "      <td>1672.869967</td>\n",
       "      <td>266.730664</td>\n",
       "      <td>72131.745801</td>\n",
       "      <td>1240.648872</td>\n",
       "      <td>6676.780389</td>\n",
       "      <td>94843.078163</td>\n",
       "      <td>2129.095614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1313.573364</td>\n",
       "      <td>-1360.943115</td>\n",
       "      <td>33.014164</td>\n",
       "      <td>-55.349747</td>\n",
       "      <td>101.148880</td>\n",
       "      <td>6.004326</td>\n",
       "      <td>175.159637</td>\n",
       "      <td>-369.176514</td>\n",
       "      <td>208.163177</td>\n",
       "      <td>113.497681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1164.877045</td>\n",
       "      <td>49118.407943</td>\n",
       "      <td>1287.060051</td>\n",
       "      <td>187.659418</td>\n",
       "      <td>72411.716651</td>\n",
       "      <td>760.862728</td>\n",
       "      <td>7089.119024</td>\n",
       "      <td>95011.811134</td>\n",
       "      <td>2030.397039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2542.413330</td>\n",
       "      <td>-794.536133</td>\n",
       "      <td>245.316132</td>\n",
       "      <td>-268.127106</td>\n",
       "      <td>102.290421</td>\n",
       "      <td>-488.487335</td>\n",
       "      <td>119.743805</td>\n",
       "      <td>-526.833801</td>\n",
       "      <td>833.238159</td>\n",
       "      <td>-147.713013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1469.750435</td>\n",
       "      <td>49007.455167</td>\n",
       "      <td>1599.635920</td>\n",
       "      <td>430.372908</td>\n",
       "      <td>72465.263449</td>\n",
       "      <td>979.332605</td>\n",
       "      <td>6787.478675</td>\n",
       "      <td>95143.129147</td>\n",
       "      <td>2280.495642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6699.755371</td>\n",
       "      <td>2747.739746</td>\n",
       "      <td>-3168.123047</td>\n",
       "      <td>-2014.046753</td>\n",
       "      <td>2157.230225</td>\n",
       "      <td>290.348938</td>\n",
       "      <td>2590.269287</td>\n",
       "      <td>625.252075</td>\n",
       "      <td>-120.761475</td>\n",
       "      <td>-931.633545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3223 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pscores_bin  dist_osm_fclass_tertiary_meters  \\\n",
       "0     2.0          3792.357952                       \n",
       "1     1.0          3165.949020                       \n",
       "2     1.0          3014.708699                       \n",
       "3     3.0          3066.888739                       \n",
       "4     1.0          3089.591174                       \n",
       "...   ...                  ...                       \n",
       "3218  1.0          1914.085972                       \n",
       "3219  0.0          1649.096528                       \n",
       "3220  0.0          1598.886011                       \n",
       "3221  0.0          1164.877045                       \n",
       "3222  2.0          1469.750435                       \n",
       "\n",
       "      dist_osm_fclass_secondary_meters  dist_osm_fclass_residential_meters  \\\n",
       "0     35917.095934                      43.583917                            \n",
       "1     36611.060520                      4.980330                             \n",
       "2     36518.572312                      73.896161                            \n",
       "3     36474.995373                      24.791045                            \n",
       "4     36450.085615                      0.208842                             \n",
       "...            ...                           ...                             \n",
       "3218  48633.104101                      2016.437865                          \n",
       "3219  48705.592566                      1736.509063                          \n",
       "3220  48676.729092                      1672.869967                          \n",
       "3221  49118.407943                      1287.060051                          \n",
       "3222  49007.455167                      1599.635920                          \n",
       "\n",
       "      dist_osm_fclass_trunk_meters  dist_osm_fclass_primary_meters  \\\n",
       "0     13075.891660                  11.621799                        \n",
       "1     12488.112391                  87.400393                        \n",
       "2     12772.653817                  375.076111                       \n",
       "3     12796.758541                  400.119781                       \n",
       "4     12817.844473                  421.441879                       \n",
       "...            ...                         ...                       \n",
       "3218  631.035101                    72286.291293                     \n",
       "3219  365.050566                    72204.953064                     \n",
       "3220  266.730664                    72131.745801                     \n",
       "3221  187.659418                    72411.716651                     \n",
       "3222  430.372908                    72465.263449                     \n",
       "\n",
       "      dist_osm_fclass_unclassified_meters  dist_osm_fclass_service_meters  \\\n",
       "0     11474.921382                         8160.699002                      \n",
       "1     11824.485331                         7700.984802                      \n",
       "2     11427.455346                         7392.205527                      \n",
       "3     11423.093075                         7441.220550                      \n",
       "4     11408.873066                         7457.007066                      \n",
       "...            ...                                 ...                      \n",
       "3218  1445.935959                          6340.847990                      \n",
       "3219  1248.008186                          6614.281203                      \n",
       "3220  1240.648872                          6676.780389                      \n",
       "3221  760.862728                           7089.119024                      \n",
       "3222  979.332605                           6787.478675                      \n",
       "\n",
       "      dist_osm_fclass_motorway_meters  dist_osm_fclass_living_street_meters  \\\n",
       "0     149159.485989                    15756.970525                           \n",
       "1     148553.674436                    15796.078642                           \n",
       "2     148370.227522                    16233.078724                           \n",
       "3     148422.609270                    16205.552093                           \n",
       "4     148443.676013                    16204.936983                           \n",
       "...             ...                             ...                           \n",
       "3218  95081.405194                     2500.320481                            \n",
       "3219  94930.990709                     2226.293917                            \n",
       "3220  94843.078163                     2129.095614                            \n",
       "3221  95011.811134                     2030.397039                            \n",
       "3222  95143.129147                     2280.495642                            \n",
       "\n",
       "      estimate_dau_all  estimate_dau_male  estimate_dau_female         pc_0  \\\n",
       "0     0                 0                  0                    7585.058105   \n",
       "1     0                 0                  0                    4837.711914   \n",
       "2     0                 0                  0                    2020.174561   \n",
       "3     0                 0                  0                    2020.174561   \n",
       "4     0                 0                  0                    2020.174561   \n",
       "...  ..                ..                 ..                            ...   \n",
       "3218  0                 0                  0                    1313.573364   \n",
       "3219  0                 0                  0                    1313.573364   \n",
       "3220  0                 0                  0                    1313.573364   \n",
       "3221  0                 0                  0                    2542.413330   \n",
       "3222  0                 0                  0                    6699.755371   \n",
       "\n",
       "             pc_1         pc_2         pc_3         pc_4         pc_5  \\\n",
       "0     3182.068115  3086.048584  362.265961  -3541.786865  651.376221    \n",
       "1     1970.663086  894.096558   1319.076172  118.324799  -1669.840210   \n",
       "2    -1018.420105  222.295380  -434.918549  -168.401978  -306.019714    \n",
       "3    -1018.420105  222.295380  -434.918549  -168.401978  -306.019714    \n",
       "4    -1018.420105  222.295380  -434.918549  -168.401978  -306.019714    \n",
       "...           ...         ...          ...          ...          ...    \n",
       "3218 -1360.943115  33.014164   -55.349747    101.148880   6.004326      \n",
       "3219 -1360.943115  33.014164   -55.349747    101.148880   6.004326      \n",
       "3220 -1360.943115  33.014164   -55.349747    101.148880   6.004326      \n",
       "3221 -794.536133   245.316132  -268.127106   102.290421  -488.487335    \n",
       "3222  2747.739746 -3168.123047 -2014.046753  2157.230225  290.348938    \n",
       "\n",
       "             pc_6         pc_7         pc_8         pc_9  \n",
       "0    -972.357178   1833.468628  1186.738892 -1297.999023  \n",
       "1    -379.808899  -204.805176  -774.786316  -286.413635   \n",
       "2     549.116760  -371.548248  -162.468506   139.214325   \n",
       "3     549.116760  -371.548248  -162.468506   139.214325   \n",
       "4     549.116760  -371.548248  -162.468506   139.214325   \n",
       "...          ...          ...          ...          ...   \n",
       "3218  175.159637  -369.176514   208.163177   113.497681   \n",
       "3219  175.159637  -369.176514   208.163177   113.497681   \n",
       "3220  175.159637  -369.176514   208.163177   113.497681   \n",
       "3221  119.743805  -526.833801   833.238159  -147.713013   \n",
       "3222  2590.269287  625.252075  -120.761475  -931.633545   \n",
       "\n",
       "[3223 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_final.join(df_features_pca).drop(columns=['pscores'])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split data into test/train and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'pscores_bin'\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Separate feature sets from label sets\n",
    "x_df = df_final.drop(labels=[LABEL], axis=1)\n",
    "y_df = df_final[LABEL]\n",
    "\n",
    "# Split into test and train sets for features and labels\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x_df, y_df, test_size=TEST_SIZE)\n",
    "\n",
    "# Normalize\n",
    "x_scaler = StandardScaler().fit(x_train)\n",
    "for df in (x_train, x_test):\n",
    "    x_scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_osm_fclass_tertiary_meters</th>\n",
       "      <th>dist_osm_fclass_secondary_meters</th>\n",
       "      <th>dist_osm_fclass_residential_meters</th>\n",
       "      <th>dist_osm_fclass_trunk_meters</th>\n",
       "      <th>dist_osm_fclass_primary_meters</th>\n",
       "      <th>dist_osm_fclass_unclassified_meters</th>\n",
       "      <th>dist_osm_fclass_service_meters</th>\n",
       "      <th>dist_osm_fclass_motorway_meters</th>\n",
       "      <th>dist_osm_fclass_living_street_meters</th>\n",
       "      <th>estimate_dau_all</th>\n",
       "      <th>estimate_dau_male</th>\n",
       "      <th>estimate_dau_female</th>\n",
       "      <th>pc_0</th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "      <th>pc_3</th>\n",
       "      <th>pc_4</th>\n",
       "      <th>pc_5</th>\n",
       "      <th>pc_6</th>\n",
       "      <th>pc_7</th>\n",
       "      <th>pc_8</th>\n",
       "      <th>pc_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>4080.043533</td>\n",
       "      <td>2343.932526</td>\n",
       "      <td>296.721710</td>\n",
       "      <td>591.805263</td>\n",
       "      <td>49.361803</td>\n",
       "      <td>226.736109</td>\n",
       "      <td>2027.365930</td>\n",
       "      <td>9209.895122</td>\n",
       "      <td>1105.497084</td>\n",
       "      <td>31205</td>\n",
       "      <td>26549</td>\n",
       "      <td>3548</td>\n",
       "      <td>1477.397827</td>\n",
       "      <td>-1254.490601</td>\n",
       "      <td>80.117615</td>\n",
       "      <td>-328.625671</td>\n",
       "      <td>58.844505</td>\n",
       "      <td>-92.195480</td>\n",
       "      <td>149.558472</td>\n",
       "      <td>-164.518005</td>\n",
       "      <td>-156.788864</td>\n",
       "      <td>134.899948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>5410.609315</td>\n",
       "      <td>158.314243</td>\n",
       "      <td>201.332628</td>\n",
       "      <td>14910.185701</td>\n",
       "      <td>2765.106343</td>\n",
       "      <td>963.572898</td>\n",
       "      <td>8668.713355</td>\n",
       "      <td>17437.344366</td>\n",
       "      <td>12717.113790</td>\n",
       "      <td>23852</td>\n",
       "      <td>21226</td>\n",
       "      <td>2191</td>\n",
       "      <td>-1404.656494</td>\n",
       "      <td>665.080566</td>\n",
       "      <td>151.558517</td>\n",
       "      <td>-531.364685</td>\n",
       "      <td>66.119141</td>\n",
       "      <td>-52.793396</td>\n",
       "      <td>-106.124298</td>\n",
       "      <td>-2.934883</td>\n",
       "      <td>-53.165848</td>\n",
       "      <td>-22.234234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>793.824464</td>\n",
       "      <td>6798.367082</td>\n",
       "      <td>3457.130264</td>\n",
       "      <td>56390.367122</td>\n",
       "      <td>6353.661340</td>\n",
       "      <td>6414.416747</td>\n",
       "      <td>21922.277277</td>\n",
       "      <td>71508.022384</td>\n",
       "      <td>43917.342663</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-664.024414</td>\n",
       "      <td>-30.341080</td>\n",
       "      <td>-98.783577</td>\n",
       "      <td>271.327881</td>\n",
       "      <td>47.801414</td>\n",
       "      <td>119.108185</td>\n",
       "      <td>86.558968</td>\n",
       "      <td>53.291973</td>\n",
       "      <td>70.402016</td>\n",
       "      <td>221.993179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>662.081073</td>\n",
       "      <td>926.633075</td>\n",
       "      <td>2133.255973</td>\n",
       "      <td>21353.161326</td>\n",
       "      <td>21391.012153</td>\n",
       "      <td>3826.062627</td>\n",
       "      <td>2369.657124</td>\n",
       "      <td>24682.537650</td>\n",
       "      <td>20116.032975</td>\n",
       "      <td>497</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>2142.620361</td>\n",
       "      <td>-1218.337036</td>\n",
       "      <td>426.332703</td>\n",
       "      <td>-1043.459839</td>\n",
       "      <td>-257.809601</td>\n",
       "      <td>-742.840393</td>\n",
       "      <td>17.202621</td>\n",
       "      <td>786.226807</td>\n",
       "      <td>-100.399811</td>\n",
       "      <td>316.207367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>55.519999</td>\n",
       "      <td>38.849346</td>\n",
       "      <td>101.520531</td>\n",
       "      <td>5474.384602</td>\n",
       "      <td>543.350949</td>\n",
       "      <td>1253.304736</td>\n",
       "      <td>25991.794222</td>\n",
       "      <td>71523.881235</td>\n",
       "      <td>21194.771210</td>\n",
       "      <td>24183</td>\n",
       "      <td>19390</td>\n",
       "      <td>6158</td>\n",
       "      <td>1131.108765</td>\n",
       "      <td>-1478.984741</td>\n",
       "      <td>29.505001</td>\n",
       "      <td>-144.230560</td>\n",
       "      <td>216.604294</td>\n",
       "      <td>241.564331</td>\n",
       "      <td>-103.922745</td>\n",
       "      <td>-186.295334</td>\n",
       "      <td>-40.866127</td>\n",
       "      <td>-41.888023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dist_osm_fclass_tertiary_meters  dist_osm_fclass_secondary_meters  \\\n",
       "400   4080.043533                      2343.932526                        \n",
       "317   5410.609315                      158.314243                         \n",
       "3063  793.824464                       6798.367082                        \n",
       "3099  662.081073                       926.633075                         \n",
       "2567  55.519999                        38.849346                          \n",
       "\n",
       "      dist_osm_fclass_residential_meters  dist_osm_fclass_trunk_meters  \\\n",
       "400   296.721710                          591.805263                     \n",
       "317   201.332628                          14910.185701                   \n",
       "3063  3457.130264                         56390.367122                   \n",
       "3099  2133.255973                         21353.161326                   \n",
       "2567  101.520531                          5474.384602                    \n",
       "\n",
       "      dist_osm_fclass_primary_meters  dist_osm_fclass_unclassified_meters  \\\n",
       "400   49.361803                       226.736109                            \n",
       "317   2765.106343                     963.572898                            \n",
       "3063  6353.661340                     6414.416747                           \n",
       "3099  21391.012153                    3826.062627                           \n",
       "2567  543.350949                      1253.304736                           \n",
       "\n",
       "      dist_osm_fclass_service_meters  dist_osm_fclass_motorway_meters  \\\n",
       "400   2027.365930                     9209.895122                       \n",
       "317   8668.713355                     17437.344366                      \n",
       "3063  21922.277277                    71508.022384                      \n",
       "3099  2369.657124                     24682.537650                      \n",
       "2567  25991.794222                    71523.881235                      \n",
       "\n",
       "      dist_osm_fclass_living_street_meters  estimate_dau_all  \\\n",
       "400   1105.497084                           31205              \n",
       "317   12717.113790                          23852              \n",
       "3063  43917.342663                          989                \n",
       "3099  20116.032975                          497                \n",
       "2567  21194.771210                          24183              \n",
       "\n",
       "      estimate_dau_male  estimate_dau_female         pc_0         pc_1  \\\n",
       "400   26549              3548                 1477.397827 -1254.490601   \n",
       "317   21226              2191                -1404.656494  665.080566    \n",
       "3063  0                  0                   -664.024414  -30.341080     \n",
       "3099  332                0                    2142.620361 -1218.337036   \n",
       "2567  19390              6158                 1131.108765 -1478.984741   \n",
       "\n",
       "            pc_2         pc_3        pc_4        pc_5        pc_6        pc_7  \\\n",
       "400   80.117615  -328.625671   58.844505  -92.195480   149.558472 -164.518005   \n",
       "317   151.558517 -531.364685   66.119141  -52.793396  -106.124298 -2.934883     \n",
       "3063 -98.783577   271.327881   47.801414   119.108185  86.558968   53.291973    \n",
       "3099  426.332703 -1043.459839 -257.809601 -742.840393  17.202621   786.226807   \n",
       "2567  29.505001  -144.230560   216.604294  241.564331 -103.922745 -186.295334   \n",
       "\n",
       "            pc_8        pc_9  \n",
       "400  -156.788864  134.899948  \n",
       "317  -53.165848  -22.234234   \n",
       "3063  70.402016   221.993179  \n",
       "3099 -100.399811  316.207367  \n",
       "2567 -40.866127  -41.888023   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train lengths match? True\n",
      "Test lengths match? True\n",
      "1.0    772\n",
      "2.0    653\n",
      "0.0    545\n",
      "3.0    451\n",
      "4.0    157\n",
      "Name: pscores_bin, dtype: int64\n",
      "1.0    185\n",
      "2.0    168\n",
      "0.0    146\n",
      "3.0    110\n",
      "4.0    36 \n",
      "Name: pscores_bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check lengths\n",
    "print('Train lengths match? {}'.format(len(x_train) == len(y_train)))\n",
    "print('Test lengths match? {}'.format(len(x_test) == len(y_test)))\n",
    "\n",
    "# Check target values\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train and Evaluate Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using code in run_grid.py\n",
    "from run_grid import train_models, evaluate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 16:50:19.439518 Model 1: Training LinearSVC on EXTRACTED_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.462762 Model 2: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.490851 Model 3: Training LinearSVC on EXTRACTED_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.536527 Model 4: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 0.01, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.609990 Model 5: Training LinearSVC on EXTRACTED_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.626542 Model 6: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.652522 Model 7: Training LinearSVC on EXTRACTED_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.713840 Model 8: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 1, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.786640 Model 9: Training LinearSVC on EXTRACTED_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.803777 Model 10: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'epsilon_insensitive', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.830843 Model 11: Training LinearSVC on EXTRACTED_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.892099 Model 12: Training LinearSVC on ALL_FEATURES with params {'penalty': 'l2', 'C': 2, 'loss': 'squared_hinge', 'max_iter': 10.0, 'random_state': 0}\n",
      "2020-08-10 16:50:19.997057 Saving data to output/LinearSVC_trained.pkl\n",
      "2020-08-10 16:50:19.997822 Model 13: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.016188 Model 14: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 1, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.046734 Model 15: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.074729 Model 16: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 2, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.104567 Model 17: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.133019 Model 18: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.162801 Model 19: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.190572 Model 20: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.223658 Model 21: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.249249 Model 22: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.282047 Model 23: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.317488 Model 24: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.366546 Model 25: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.432558 Model 26: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.502828 Model 27: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.548963 Model 28: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 30, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.615287 Model 29: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.671520 Model 30: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 50, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.731294 Model 31: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.781610 Model 32: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 70, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.844055 Model 33: Training DecisionTreeClassifier on EXTRACTED_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.904388 Model 34: Training DecisionTreeClassifier on ALL_FEATURES with params {'criterion': 'gini', 'splitter': 'best', 'max_depth': 100, 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 16:50:20.999622 Saving data to output/DecisionTreeClassifier_trained.pkl\n",
      "2020-08-10 16:50:21.000356 Model 35: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:27.779563 Model 36: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:28.144388 Model 37: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:28.406910 Model 38: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:28.826895 Model 39: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:29.117335 Model 40: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:29.511540 Model 41: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:29.871073 Model 42: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:30.324966 Model 43: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 16:50:30.635748 Model 44: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:31.198577 Model 45: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:31.685544 Model 46: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 10, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:32.553946 Model 47: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:33.422086 Model 48: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 50, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:34.465279 Model 49: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:35.376422 Model 50: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 50, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:36.655825 Model 51: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:37.692262 Model 52: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 50, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:39.329534 Model 53: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:40.509173 Model 54: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 50, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:42.339973 Model 55: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:43.633927 Model 56: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 50, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:45.877116 Model 57: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:47.912118 Model 58: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 50, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:51.684139 Model 59: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:53.240646 Model 60: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:55.153089 Model 61: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:56.953394 Model 62: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:50:59.448608 Model 63: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:01.502664 Model 64: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:04.328487 Model 65: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:06.506779 Model 66: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:09.794832 Model 67: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:12.166709 Model 68: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:16.336559 Model 69: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:20.303023 Model 70: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 100, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:27.186763 Model 71: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:40.789701 Model 72: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.1, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:51:57.554333 Model 73: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:52:14.022108 Model 74: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.2, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:52:36.635255 Model 75: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:52:54.837735 Model 76: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.3, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:53:22.995336 Model 77: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 16:53:47.566059 Model 78: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.4, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 17:36:38.283469 Model 79: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 17:37:08.968572 Model 80: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 0.5, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 17:37:50.663910 Model 81: Training BaggingClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 17:38:29.181819 Model 82: Training BaggingClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'max_features': 1.0, 'random_state': 0, 'n_jobs': -1}\n",
      "2020-08-10 17:40:21.768485 Saving data to output/BaggingClassifier_trained.pkl\n",
      "2020-08-10 17:40:21.770747 Model 83: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 17:40:23.902720 Model 84: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 17:40:24.083499 Model 85: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 17:40:24.246257 Model 86: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 17:40:24.530614 Model 87: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 17:40:24.792309 Model 88: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 17:40:25.317244 Model 89: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 17:40:25.617621 Model 90: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 17:40:26.205289 Model 91: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 17:40:26.574604 Model 92: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:43.026226 Model 93: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:43.896704 Model 94: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 5, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:44.940505 Model 95: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 18:17:45.076832 Model 96: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 18:17:45.180036 Model 97: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:45.274117 Model 98: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:45.441547 Model 99: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:45.614112 Model 100: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:45.971952 Model 101: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:46.150159 Model 102: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:17:46.514602 Model 103: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:46.752908 Model 104: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:47.273968 Model 105: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:47.527415 Model 106: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:48.130054 Model 107: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 18:17:48.389369 Model 108: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 18:17:48.815522 Model 109: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:49.179809 Model 110: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:49.878867 Model 111: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:50.687246 Model 112: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:17:52.542608 Model 113: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:18:07.428996 Model 114: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:18:15.232078 Model 115: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:18:22.518495 Model 116: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:18:33.776737 Model 117: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:18:40.672148 Model 118: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 50, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:18:52.463931 Model 119: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 18:18:55.570779 Model 120: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': None, 'random_state': 0}\n",
      "2020-08-10 18:18:59.065957 Model 121: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:19:02.225929 Model 122: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:19:08.139860 Model 123: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:19:13.990461 Model 124: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:19:25.466934 Model 125: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:19:31.597180 Model 126: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:19:46.049995 Model 127: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:19:55.486684 Model 128: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:20:13.319336 Model 129: Training AdaBoostClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:20:23.881124 Model 130: Training AdaBoostClassifier on ALL_FEATURES with params {'n_estimators': 100, 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'random_state': 0}\n",
      "2020-08-10 18:20:42.722359 Saving data to output/AdaBoostClassifier_trained.pkl\n",
      "2020-08-10 18:20:42.722758 Model 131: Training KNeighborsClassifier on EXTRACTED_FEATURES with params {'n_neighbors': 2}\n",
      "2020-08-10 18:20:42.790635 Model 132: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 2}\n",
      "2020-08-10 18:20:42.818610 Model 133: Training KNeighborsClassifier on EXTRACTED_FEATURES with params {'n_neighbors': 5}\n",
      "2020-08-10 18:20:42.833677 Model 134: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 5}\n",
      "2020-08-10 18:20:42.855190 Model 135: Training KNeighborsClassifier on EXTRACTED_FEATURES with params {'n_neighbors': 10}\n",
      "2020-08-10 18:20:42.868768 Model 136: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 10}\n",
      "2020-08-10 18:20:42.889800 Model 137: Training KNeighborsClassifier on EXTRACTED_FEATURES with params {'n_neighbors': 15}\n",
      "2020-08-10 18:20:42.905268 Model 138: Training KNeighborsClassifier on ALL_FEATURES with params {'n_neighbors': 15}\n",
      "2020-08-10 18:20:42.953218 Saving data to output/KNeighborsClassifier_trained.pkl\n",
      "2020-08-10 18:20:42.953951 Model 139: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:43.102103 Model 140: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:43.234892 Model 141: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:43.364418 Model 142: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:43.494482 Model 143: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:43.624849 Model 144: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:20:43.755320 Model 145: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:43.885631 Model 146: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:44.013367 Model 147: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:44.147239 Model 148: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:44.273202 Model 149: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:44.412317 Model 150: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:44.652602 Model 151: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:44.780279 Model 152: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:44.934559 Model 153: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:45.065970 Model 154: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:45.197120 Model 155: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:45.338773 Model 156: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:45.583833 Model 157: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:45.712404 Model 158: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:45.838905 Model 159: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:45.968505 Model 160: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:46.096144 Model 161: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:46.228982 Model 162: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:46.456114 Model 163: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:46.586042 Model 164: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:46.712346 Model 165: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:46.845219 Model 166: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:46.971917 Model 167: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:47.099864 Model 168: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:47.444774 Model 169: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:47.578827 Model 170: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:47.705285 Model 171: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:47.837712 Model 172: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:47.969435 Model 173: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:48.205824 Model 174: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:48.546312 Model 175: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:48.670608 Model 176: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:48.796005 Model 177: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:48.929138 Model 178: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:49.056342 Model 179: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:49.288187 Model 180: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:49.635156 Model 181: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:49.762399 Model 182: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:49.888616 Model 183: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:50.018737 Model 184: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:20:50.148408 Model 185: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:50.382096 Model 186: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:50.722750 Model 187: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:50.847454 Model 188: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:50.979001 Model 189: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:51.109121 Model 190: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:51.236875 Model 191: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:51.469010 Model 192: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:51.811417 Model 193: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:51.941314 Model 194: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:52.069380 Model 195: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:52.199380 Model 196: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:52.328916 Model 197: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:52.565349 Model 198: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:53.009972 Model 199: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:53.144971 Model 200: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:53.286007 Model 201: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:53.422012 Model 202: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:53.562566 Model 203: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:53.706979 Model 204: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:53.951623 Model 205: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:54.086216 Model 206: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:54.229117 Model 207: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:54.369407 Model 208: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:54.508369 Model 209: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:54.755056 Model 210: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:55.004336 Model 211: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:55.154621 Model 212: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:55.293677 Model 213: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:55.438640 Model 214: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:55.579037 Model 215: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:55.823604 Model 216: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:56.192818 Model 217: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:56.332197 Model 218: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:56.584653 Model 219: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:56.729736 Model 220: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:56.977656 Model 221: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:57.221973 Model 222: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:57.685312 Model 223: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:57.827776 Model 224: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:20:58.068959 Model 225: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:58.206476 Model 226: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:58.456128 Model 227: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:58.696674 Model 228: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:59.161633 Model 229: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:59.402370 Model 230: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:59.657165 Model 231: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:20:59.900552 Model 232: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:00.155898 Model 233: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:00.525610 Model 234: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:01.081753 Model 235: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:01.325088 Model 236: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:01.572401 Model 237: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:01.820491 Model 238: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:02.070935 Model 239: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:02.422506 Model 240: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:02.972714 Model 241: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:03.217002 Model 242: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:03.469693 Model 243: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:03.720480 Model 244: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:03.973364 Model 245: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:04.328999 Model 246: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:04.973975 Model 247: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:05.213519 Model 248: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:05.471009 Model 249: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:05.722289 Model 250: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:05.972482 Model 251: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:06.329156 Model 252: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:06.977129 Model 253: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:07.219509 Model 254: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:07.472974 Model 255: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:07.724899 Model 256: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:07.979841 Model 257: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:08.429877 Model 258: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 10, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:09.194591 Model 259: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:10.114502 Model 260: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:11.035375 Model 261: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:11.850677 Model 262: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:21:12.769003 Model 263: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:13.685526 Model 264: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:14.795368 Model 265: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:15.699437 Model 266: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:16.613901 Model 267: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:17.523496 Model 268: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:18.446229 Model 269: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:19.467405 Model 270: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:20.894595 Model 271: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:21.806487 Model 272: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:22.819444 Model 273: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:23.731768 Model 274: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:24.643978 Model 275: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:25.863880 Model 276: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:27.812314 Model 277: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:28.828215 Model 278: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:29.858328 Model 279: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:30.869301 Model 280: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:31.886129 Model 281: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:33.321245 Model 282: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:35.605512 Model 283: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:36.607049 Model 284: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:37.726126 Model 285: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:38.746898 Model 286: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:39.865129 Model 287: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:41.490845 Model 288: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:44.158764 Model 289: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:45.275840 Model 290: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:46.404991 Model 291: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:47.629695 Model 292: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:48.863191 Model 293: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:50.699506 Model 294: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:53.792558 Model 295: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:55.014534 Model 296: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:56.250968 Model 297: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:57.366295 Model 298: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:21:58.597362 Model 299: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:00.535863 Model 300: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:22:04.032122 Model 301: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:05.248929 Model 302: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:06.568187 Model 303: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:07.785798 Model 304: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:09.325959 Model 305: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:11.989382 Model 306: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:16.816766 Model 307: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:18.300824 Model 308: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:19.979812 Model 309: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:21.549803 Model 310: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:23.238060 Model 311: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:26.036142 Model 312: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:31.209582 Model 313: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:32.779876 Model 314: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:34.582092 Model 315: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:36.161578 Model 316: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:37.947389 Model 317: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:40.956873 Model 318: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:46.017298 Model 319: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:22:54.160550 Model 320: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:23:02.161565 Model 321: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:23:10.031876 Model 322: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:23:19.172200 Model 323: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:23:27.627936 Model 324: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:23:37.551818 Model 325: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:23:45.697299 Model 326: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:23:53.872549 Model 327: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:24:19.791518 Model 328: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:24:22.804444 Model 329: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:24:26.025822 Model 330: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:24:56.077863 Model 331: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:25:09.548506 Model 332: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:25:23.061182 Model 333: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:25:34.576497 Model 334: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:25:44.194174 Model 335: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:26:01.835483 Model 336: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:26:24.897696 Model 337: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:26:34.617336 Model 338: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:26:44.799931 Model 339: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:26:54.527786 Model 340: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:27:05.097939 Model 341: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:27:20.977857 Model 342: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:27:42.969816 Model 343: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:27:52.499755 Model 344: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:28:02.732574 Model 345: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:28:12.266474 Model 346: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:28:22.411752 Model 347: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:28:37.388358 Model 348: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:29:03.550596 Model 349: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:29:13.669064 Model 350: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:29:24.633688 Model 351: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:29:34.749441 Model 352: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:29:45.721405 Model 353: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:30:03.015545 Model 354: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:30:33.308880 Model 355: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:30:44.054920 Model 356: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:30:55.754865 Model 357: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:31:06.794341 Model 358: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:31:19.616626 Model 359: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:31:38.488193 Model 360: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:32:12.818396 Model 361: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:32:24.206101 Model 362: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:32:36.729272 Model 363: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:32:48.227519 Model 364: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:33:01.818311 Model 365: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:33:22.826729 Model 366: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:34:00.139949 Model 367: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:34:12.130909 Model 368: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:34:25.379165 Model 369: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:34:37.519090 Model 370: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:34:50.645590 Model 371: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:35:13.226469 Model 372: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:35:53.356063 Model 373: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:36:05.654212 Model 374: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:36:19.796892 Model 375: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:36:32.155260 Model 376: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 18:36:46.025125 Model 377: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:37:09.834226 Model 378: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:37:54.519844 Model 379: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:38:30.914212 Model 380: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:39:07.253429 Model 381: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:39:43.200192 Model 382: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:40:19.622211 Model 383: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:41:00.534452 Model 384: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 1, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:41:47.906428 Model 385: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:42:29.227567 Model 386: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:43:08.178342 Model 387: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:43:45.598620 Model 388: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:44:23.209422 Model 389: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:45:08.691241 Model 390: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:46:15.520983 Model 391: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:47:02.553331 Model 392: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:47:42.831248 Model 393: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:48:21.689230 Model 394: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:49:03.632561 Model 395: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:49:57.636272 Model 396: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:51:30.779586 Model 397: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:52:12.254697 Model 398: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:52:55.462999 Model 399: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:53:36.838827 Model 400: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:54:19.949879 Model 401: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:55:23.489237 Model 402: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 18:57:08.867039 Model 403: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:17:31.189992 Model 404: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:18:29.532701 Model 405: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:19:18.153369 Model 406: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:20:08.444898 Model 407: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:21:24.455981 Model 408: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:38:38.905056 Model 409: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:39:26.968714 Model 410: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:40:19.448955 Model 411: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:58:41.665884 Model 412: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 19:59:58.119072 Model 413: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:01:22.863485 Model 414: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 20:04:00.405040 Model 415: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:04:50.270891 Model 416: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:05:47.475330 Model 417: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:06:38.332923 Model 418: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 7, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:07:33.098829 Model 419: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:08:58.127815 Model 420: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 7, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:11:33.095471 Model 421: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:12:24.961580 Model 422: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:13:22.153281 Model 423: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:14:14.933823 Model 424: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 8, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:15:12.408200 Model 425: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:16:45.740287 Model 426: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:19:56.565272 Model 427: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:20:53.119548 Model 428: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:21:58.697230 Model 429: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:22:54.330704 Model 430: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 9, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:23:55.837161 Model 431: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:25:36.695054 Model 432: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 9, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:28:51.493259 Model 433: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:29:51.210713 Model 434: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:30:55.622487 Model 435: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:31:55.378639 Model 436: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:33:06.645458 Model 437: Training RandomForestClassifier on EXTRACTED_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:34:53.966948 Model 438: Training RandomForestClassifier on ALL_FEATURES with params {'n_estimators': 5000, 'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_jobs': -1, 'random_state': 0}\n",
      "2020-08-10 20:43:16.742850 Saving data to output/RandomForestClassifier_trained.pkl\n",
      "2020-08-10 20:43:16.762491 Model 439: Training GradientBoostingClassifier on EXTRACTED_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 20:43:40.424034 Model 440: Training GradientBoostingClassifier on ALL_FEATURES with params {'loss': 'deviance', 'learning_rate': 0.0001, 'n_estimators': 100, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'random_state': 0}\n",
      "2020-08-10 20:43:47.385591 Saving data to output/GradientBoostingClassifier_trained.pkl\n",
      "2020-08-10 20:43:47.485076    Evaluating GradientBoostingClassifier_trained.pkl\n",
      "2020-08-10 20:43:47.824061    Evaluating DecisionTreeClassifier_trained.pkl\n",
      "2020-08-10 20:43:48.916900    Evaluating RandomForestClassifier_trained.pkl\n",
      "2020-08-10 20:53:48.669724    Evaluating KNeighborsClassifier_trained.pkl\n",
      "2020-08-10 20:54:13.799610    Evaluating SVC_trained.pkl\n",
      "2020-08-10 20:54:13.805246    Evaluating BaggingClassifier_trained.pkl\n",
      "2020-08-10 20:55:55.673862    Evaluating AdaBoostClassifier_trained.pkl\n",
      "2020-08-10 20:56:02.173566    Evaluating LinearSVC_trained.pkl\n"
     ]
    }
   ],
   "source": [
    "# DEFINE FEATURE GROUPS\n",
    "feature_dict = {'EXTRACTED_FEATURES': df_final.filter(regex='pc').columns.tolist(),\n",
    "                'ALL_FEATURES': x_df.columns.tolist()}\n",
    "\n",
    "# TRAIN MODELS AND EXPORT ERRORS\n",
    "parameters = cf.GRID_MAIN_CLASS\n",
    "training_errors = train_models(parameters, x_train, y_train, feature_dict, verbose=True)\n",
    "training_errors.to_csv(os.path.join('output', 'errors.csv'))\n",
    "\n",
    "# PREDICT LABELS AND EVALUATE RESULTS\n",
    "trained_obj_list = [f for f in os.listdir('output') if f.endswith('_trained.pkl')]\n",
    "results_df = evaluate_models(trained_obj_list, x_test, y_test, feature_dict)\n",
    "results_df.to_csv(os.path.join('output', 'results.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
